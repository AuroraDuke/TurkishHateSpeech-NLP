{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c617721-2283-4c70-a8ca-de87c4a38a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa3d6c3-8eb2-489e-9c99-462addd4432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\"HateSpeechTurkish.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaee7af9-5f14-4de1-864b-2259de9c3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the existing KeyedVectors model\n",
    "current_dir = os.getcwd()\n",
    "model_path = os.path.join(current_dir, \"turkishword2vec\", \"trmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e031ff65-0492-46ba-9a40-1d9d0cf55bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc453502-2564-4d47-9c03-55bdae78eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('atilla', 0.42598018050193787), ('itü', 0.41031748056411743), ('ayhan', 0.4089619219303131), ('sönmez', 0.40660181641578674), ('seyfi', 0.40342816710472107), ('nevzat', 0.3952556550502777), ('irfan', 0.3949110209941864), ('ülkü', 0.3936089277267456), ('şener', 0.3935551047325134), ('vedat', 0.392831951379776)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=[\"türkiye\", \"türk\"], negative=[\"suriye\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a18b21c-5d32-4165-a0e9-1b1a3a2749ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert KeyedVectors to a trainable Word2Vec format\n",
    "word2vec_model = Word2Vec(vector_size=word_vectors.vector_size, min_count=1)\n",
    "word2vec_model.build_vocab([list(word_vectors.index_to_key)])  \n",
    "word2vec_model.wv.vectors = word_vectors.vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5342db2d-7d7b-414c-b64c-4c381e2cd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(sentence):\n",
    "    \"\"\"\n",
    "    Cümleyi tokenize eder ve 3 harften az olan kelimeleri filtreler.\n",
    "    \"\"\"\n",
    "    tokens = simple_preprocess(sentence)\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 3]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53027eb1-9e5c-4b9c-9801-ac9e4117c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'tweet' column using the custom function\n",
    "tokenized_sentences = df_main['correct_normalize_tweet'].apply(custom_tokenize).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49bcca06-fd6f-437c-a9f0-12b73c003ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 10224\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences:\", len(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2f44e6-ba38-4ffe-b149-66421ba9a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 170330\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total tokens\n",
    "tokens_per_sentence = [len(sentence) for sentence in tokenized_sentences]  # Tokens per sentence\n",
    "total_tokens = sum(tokens_per_sentence)\n",
    "\n",
    "# Display the total and average tokens\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bbdb0e0-3f53-4cc1-9e03-bad2e7279648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655730, 681320)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Update the vocabulary with new training data and fine-tune the model\n",
    "word2vec_model.build_vocab(tokenized_sentences, update=True)\n",
    "word2vec_model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f214f9b-ead8-4bbc-903d-09b08533cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert the fine-tuned model back to KeyedVectors format\n",
    "fine_tuned_word_vectors = word2vec_model.wv  # Sadece kelime vektörleri alınır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138a43cf-c117-4d06-b621-a14253838c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune edilmiş modelin ilişkileri:\n",
      "[('türkdemek', 0.9047353863716125), ('ülkede', 0.9018970727920532), ('hristiyan', 0.8950584530830383), ('yahudilerdin', 0.8918371200561523), ('şerefsizler', 0.8900843262672424), ('rterdoğan', 0.8895334005355835), ('türkmenlerdi', 0.8853127956390381), ('yemde', 0.8845551609992981), ('enineboyuna', 0.8845038414001465), ('deiste', 0.8841897249221802)]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Test the fine-tuned model\n",
    "print(\"Fine-tune edilmiş modelin ilişkileri:\")\n",
    "print(fine_tuned_word_vectors.most_similar(positive=[\"türkiye\", \"türk\"], negative=[\"suriye\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce18c1e8-f339-468f-9d8e-1951c98dcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save the fine-tuned word vectors\n",
    "output_path = 'trhatespeechmodel_finetuned.kv'\n",
    "fine_tuned_word_vectors.save_word2vec_format(output_path, binary=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
